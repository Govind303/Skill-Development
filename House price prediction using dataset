import pandas as pd

# Sample data
data = {
    'Area': [2000, 1500, 1800, 2200, 1600, 2500, 2100, 1900, 1700, 2300],
    'Bedrooms': [3, 2, 4, 3, 2, 5, 3, 3, 2, 4],
    'Age': [5, 10, 2, 8, 15, 7, 3, 12, 20, 10],
    'Price': [300000, 250000, 350000, 400000, 240000, 500000, 420000, 280000, 230000, 460000]
}

# Create DataFrame
df = pd.DataFrame(data)

# Save DataFrame to CSV
df.to_csv('your_dataset1.csv', index=False)

print("CSV file 'your_dataset.csv' has been created.")



# Step 1: Import necessary libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns

# Step 2: Load the data (replace 'your_dataset.csv' with your actual file path)
data = pd.read_csv('your_dataset1.csv')

# Step 3: Explore the data (optional but helpful to understand the dataset)
print(data.head())  # Display first few rows of the dataset
print(data.info())  # Get info about the dataset such as datatypes and null values

# Step 4: Data Preprocessing (handle missing values if necessary)
# If there are missing values, you might need to fill or drop them:
# For simplicity, we will drop rows with missing values (you can also use data.fillna() for imputation)
data = data.dropna()

# Step 5: Define features (X) and target (y)
X = data[['Area', 'Bedrooms', 'Age']]  # Features: Area, Bedrooms, Age
y = data['Price']  # Target: Price

# Step 6: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 7: Train a Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Step 8: Make predictions on the test data
y_pred = model.predict(X_test)

# Step 9: Evaluate the model using metrics such as Mean Squared Error (MSE) and R-squared (R2)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

# Print evaluation metrics
print(f"Mean Squared Error (MSE): {mse}")
print(f"R-squared (R2): {r2}")

# Step 10: Visualize the true vs predicted prices (optional)
plt.figure(figsize=(10, 6))
sns.regplot(x=y_test, y=y_pred, scatter_kws={'s': 10}, line_kws={'color': 'red'})
plt.xlabel('True Prices')
plt.ylabel('Predicted Prices')
plt.title('True vs Predicted House Prices')
plt.show()

# Optional: Visualize the coefficients (importance of each feature)
coefficients = pd.DataFrame(model.coef_, X.columns, columns=['Coefficient'])
print("\nModel Coefficients:")
print(coefficients)
